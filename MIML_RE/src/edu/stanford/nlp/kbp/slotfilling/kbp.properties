#
# Global properties file for the KBP project
#
kbp.runid = stanford1
serializedRelationExtractorPath = kbp_relation_model
work.dir = /scr/mihais/code/javanlp/tmp
# specify trainer.model = jointbayes|localbayes|atleastonce|atleastonce_inc|lr_inc


#
# BaselineNLProcessor settings
#
# annotators is used for test queries in KBPTester and SnippetsToCache. Do NOT mess with this property!
annotators = tokenize, ssplit, pos, lemma, ner, regexner, parse, dcoref
ssplit.htmlBoundariesToDiscard = p,text,post,postdate,poster,turn,speaker,quote
parser.maxlen = 50
regexner.mapping = /u/nlp/data/TAC-KBP2010/sentence_extraction/combined_map
regexner.ignorecase = true
oldCorefFormat = true


#
# KBPReader properties
#
# mostly uncached indices, over NFS. Used to replicate TAC-KBP 2010 behavior 
#index.kbp = /u/nlp/data/TAC-KBP2010/indices/TAC_2010_KBP_Source_Data,/u/nlp/data/TAC-KBP2010/indices/enwiki-20081008-pages-articles,/u/nlp/data/TAC-KBP2010/indices/TAC_2009_KBP_Evaluation_Reference_Knowledge_Base_As_Documents_Index_Cached
#index.official = /u/nlp/data/TAC-KBP2010/indices/TAC_2010_KBP_Source_Data

# new indices over NFS, using our own customized annotation caching
index.kbp = cached,/u/nlp/data/TAC-KBP2010/indices/TAC_2010_KBP_Source_Data_Index_Cached;cached,/u/nlp/data/TAC-KBP2010/indices/TAC_2009_KBP_Evaluation_Reference_Knowledge_Base_As_Documents_Index_Cached;cached,/scr/nlp/data/tackbp2010/indices/lr_en_100622_2000_Index_Cached
index.official = /u/nlp/data/TAC-KBP2010/indices/TAC_2010_KBP_Source_Data_Index_Cached
reader.webcache = /scr/nlp/data/tackbp2010/web_snippets_caches

# new indices, local to each PBS machine. has Wikipedia UNCACHED, so try not to use this
#index.kbp = cached,/HOSTNAME/scr1/TAC-KBP2010/indices/TAC_2010_KBP_Source_Data_Index_Cached;wiki,/u/nlp/data/TAC-KBP2010/indices/lr_en_100622_2000;cached,/HOSTNAME/scr1/TAC-KBP2010/indices/TAC_2009_KBP_Evaluation_Reference_Knowledge_Base_As_Documents_Index_Cached
#index.official = /HOSTNAME/scr1/TAC-KBP2010/indices/TAC_2010_KBP_Source_Data_Index_Cached
#reader.webcache = /HOSTNAME/scr1/TAC-KBP2010/indices/web_snippets_caches

index.maxsentencelength = 50

# could be NONE, NER, TRIGGER, or BUCKETS (see IndexExtractor.java for more details)
index.train.sortmode = NONE
index.train.useknownslots = true
index.test.sortmode = BUCKETS

# Use this block for the best model (F1 ~20, trains in ~14 hrs)
#index.train.sentences.per.entity = 200
#index.train.websentences.per.entity = 500
#index.test.sentences.per.entity = 500
#index.test.websentences.per.entity = 1000
## If true, read also sentences cached in kbp.websnippets.cache
#reader.useweb = true
#index.test.usecache = false
#index.train.usecache = false
#index.cache.dir = /scr/nlp/data/tackbp2010/indices/cache
# End block

# Use this block for a quick model (F1 ~17, trains in ~2 hrs)
index.train.sentences.per.entity = 50
index.test.sentences.per.entity = 50
reader.useweb = false
index.train.usecache = true
index.test.usecache = true
index.cache.dir = /scr/nlp/data/tackbp2010/indices/mihai_cache
# End block

# number of sentences before and after the current to return as part of a match
index.context.previous = 0
index.context.next = 0

# How many extra results to consider when picking sentences.per.entity
index.extraresults.factor = 1.0
# same thing, but applied at the IndexAndWebCacheSentenceExtractor,
# which uses different sorting methods to pick the best ones
index.indexandweb.extraresults.factor = 1.0
# sort modes after combining all sentences... either sort index & web
# together or sort them separately
# see IndexAndWebCacheSentenceExtractor
index.combinemode = NO_SORTING
#index.lm = /u/nlp/data/TAC-KBP2010/lm/lm.1-8.op.ser.gz

# we might use these trigger words during feature generation (disabled by default)
relation.triggers = /u/nlp/data/TAC-KBP2010/sentence_extraction/web_queries/keywords_no_ml
reader.multimatch = true
reader.enforcene = true
reader.domain.adapt = false
# possible values: all, three, two
# - all: makes one domain for each index 
# - three: corpus, web, wiki
# - two: web, non-web
reader.domain.adapt.style = all

#
# block below relevant only for PipelineIndexExtractor, which should no longer be used (everything should be cached offline)
#
index.pipelinemethod = SPLIT
index.fullannotators = tokenize, ssplit, pos, lemma, ner, regexner, parse, dcoref
index.step1annotators = tokenize, ssplit
index.step2annotators = pos, lemma, ner, regexner, parse


#
# KBPDomReader settings
#
kbp.mapping = /u/nlp/data/TAC-KBP2010/clean_knowledge_base/docs/mapping
#kbp.ner.types = /u/nlp/data/TAC-KBP2010/sentence_extraction/NER_types.ORIGINAL
kbp.ner.types = /u/nlp/data/TAC-KBP2010/sentence_extraction/NER_types
kbp.manual.lists = /u/nlp/data/TAC-KBP2010/clean_knowledge_base/docs/manual_lists/specific_relations
kbp.countries = /u/nlp/data/TAC-KBP2010/clean_knowledge_base/docs/manual_lists/locations/countries
kbp.states = /u/nlp/data/TAC-KBP2010/clean_knowledge_base/docs/manual_lists/locations/statesandprovinces
kbp.inputkb = /u/nlp/data/TAC-KBP2010/TAC_2009_KBP_Evaluation_Reference_Knowledge_Base/data
kbp.debugkb = tmp


#
# Gazetteer info
#
nationalities = /u/nlp/data/TAC-KBP2010/nationalities/CountryLexicalResource.db
states = /u/nlp/data/TAC-KBP2010/states/state-abbreviations.txt


#
# SemgrexExtractor
#
rule.dir = /u/nlp/data/TAC-KBP2010/patterns
priority.file = /u/nlp/data/TAC-KBP2010/relation.priorities
use.statistical.model = true
use.rulebased.model = false


#
# TestSentenceCacher
# NO LONGER USED! Use LucenePipelineCacher instead!
#
# sentence caches, used ONLY when Constants.USE_OLD_CACHING = true
# below: a sentence cache local to jackfruit (valid as of 07/21/2010) 
##index.sentencecache = /jackfruit/scr1/data/TAC-KBP2010/sentence_caches/current
# store the "pipelined" sentences for each entity here
#index.sentencecache = /jackknife/scr1/data/TAC-KBP2010/sentence_caches/current

#kbp.testcache = /scr/nlp/data/tackbp2010/test_sentence_caches/current
##kbp.testqueries = /u/nlp/data/TAC-KBP2010/participant_annotation_queries.xml
##kbp.testqueries = /u/nlp/data/TAC-KBP2010/test2010/TAC_2010_KBP_Evaluation_Slot_Filling_Queries/data/tac_2010_kbp_evaluation_slot_filling_queries.xml
#kbp.testsentences.per.entity = 500

#
# WebSnippetProcessor settings (generates sentence cache from web snippets)
#
#kbp.websnippets.minsent = 15

# web snippets for the training entities in the KB (this uses kbp.inputkb as well, to map entity names to entity types)
#kbp.websnippets.dir = /scr/nlp/data/tackbp2010/web_snippets_for_slots/train.results.common
#kbp.websnippets.cache = /scr/nlp/data/tackbp2010/web_snippets_caches/train/current
#
# web snippets for the official 2011 test queries
#kbp.websnippets.entitytypes = /u/nlp/data/TAC-KBP2010/test2011/TAC_2011_KBP_English_Evaluation_Regular_Slot_Filling_Queries_V1.1/data/tac_2011_kbp_english_evaluation_regular_slot_filling_queries.xml
#kbp.websnippets.dir = /scr/nlp/data/tackbp2010/web_snippets_for_slots/test2011.results.common
#kbp.websnippets.cache = /scr/nlp/data/tackbp2010/web_snippets_caches/test/current_tmp
#
# web snippets for the official 2010 test queries
#kbp.websnippets.entitytypes = /u/nlp/data/TAC-KBP2010/test2010/TAC_2010_KBP_Evaluation_Slot_Filling_Queries/data/tac_2010_kbp_evaluation_slot_filling_queries.xml
#kbp.websnippets.dir = /scr/nlp/data/tackbp2010/web_snippets_for_slots/test2010.results.common 
#kbp.websnippets.cache = /scr/nlp/data/tackbp2010/web_snippets_caches/test/current
#
# web snippets for the official 2009 test queries (our development set)
#kbp.websnippets.entitytypes = /u/nlp/data/TAC-KBP2010/test2009/TAC_2009_KBP_Evaluation_Slot_Filling_List/data/slot_filling_query_list_noGPE.xml
#kbp.websnippets.dir = /scr/nlp/data/tackbp2010/web_snippets_for_slots/test2009.results.common 
#kbp.websnippets.cache = /scr/nlp/data/tackbp2010/web_snippets_caches/test/current
#
# web snippets for the participant annotations
#kbp.websnippets.entitytypes = /u/nlp/data/TAC-KBP2010/participant_annotation_queries.xml
#kbp.websnippets.dir = /scr/nlp/data/tackbp2010/web_snippets_for_slots/dev.results.common
#kbp.websnippets.cache = /scr/nlp/data/tackbp2010/web_snippets_caches/test/current
#


#
# ErrorAnalysis
#
## don't need NLP analysis for the non-cached indices
## do NOT set this in regular train/test runs!
#index.minimal.analysis = true
# if true, run the analysis over devQueries; otherwise, run it over the training KB set in analysis.kb
analysis.test.mode = false
# small.xml contains ~100 entities; big.xml contains ~1000 entities
analysis.kb = /u/nlp/data/TAC-KBP2010/TAC_2009_KBP_Evaluation_Reference_Knowledge_Base/stanford_splits/analysis/big.xml
# analysis.kb = /u/nlp/data/TAC-KcBP2010/TAC_2009_KBP_Evaluation_Reference_Knowledge_Base/stanford_splits/train_small0/kb_part-0001.xml
# use this property if you want a serialized map from relation name to coremap
#analysis.dumpSentences = /u/horatio/kbpsentences2.ser


#
# Model properties
#
# do not tune the acceptance threshold for a slot; accept everything
slot.threshold = 0
# keep only 5% of the negative examples; this is the best for KBP
negatives.sampleratio = 0.05
# use all negative labels; this is better when we aggresively subsample negatives
use.allnegs = true
# remove features seen less than 5 times; this makes everything much faster
featureCountThreshold = 5

# JointBayes settings (tuned on dev)
folds = 3
# epochs should be 8 for KBP or 6 for MultiR
epochs = 8
features = 1
filter = all
inference.type = stable

# AtLeastOnce settings (tuned on dev)
perceptron.epochs = 20


#
# KBPTrainer/Tester settings
#
nlpsub = true
#relationFeatures = arg_words,arg_type,dependency_path_lowlevel,dependency_path_words,surface_path_POS,entities_between_args,full_tree_path,dependency_path_POS_unigrams,dependency_path_word_n_grams,dependency_path_POS_n_grams,dependency_path_edge_lowlevel_n_grams,dependency_path_edge-node-edge-grams_lowlevel,dependency_path_node-edge-node-grams_lowlevel,dependency_path_directed_bigrams,dependency_path_edge_unigrams,same_head,entity_counts
#relationFeatures = arg_words,arg_type,arg_order,full_tree_path,surface_distance,surface_distance_bins,adjacent_words,entities_between_args,entity_counts,span_words_unigrams,dependency_path_lowlevel,dependency_path_words,arg2_number,arg2_date,span_words_trigger,dependency_path_trigger,arg_gender
relationFeatures = arg_words,arg_type,arg_order,full_tree_path,surface_distance_binary,surface_distance_bins,adjacent_words,entities_between_args,entity_counts_binary,entity_counts_bins,span_words_unigrams,dependency_path_lowlevel,dependency_path_words
# valid values: best, all
kbp.list.output = all
logLevel = SEVERE
readerLogLevel = SEVERE
# If you want to train on 10% of the KB:
# trainPath = /u/nlp/data/TAC-KBP2010/TAC_2009_KBP_Evaluation_Reference_Knowledge_Base/stanford_splits/train_small0
trainPath = /u/nlp/data/TAC-KBP2010/TAC_2009_KBP_Evaluation_Reference_Knowledge_Base/data
testPath = /u/nlp/data/TAC-KBP2010/TAC_2009_KBP_Evaluation_Reference_Knowledge_Base/stanford_splits/devel

# test queries for KBPTester from the 2010 evaluation
#devQueries = /u/nlp/data/TAC-KBP2010/test2010/TAC_2010_KBP_Evaluation_Slot_Filling_Queries/data/tac_2010_kbp_evaluation_slot_filling_queries_DEVELOPMENT.xml
#testQueries = /u/nlp/data/TAC-KBP2010/test2010/TAC_2010_KBP_Evaluation_Slot_Filling_Queries/data/tac_2010_kbp_evaluation_slot_filling_queries_TESTING_NO_SF288.xml
#kbp.goldresponses = /u/nlp/data/TAC-KBP2010/test2010/TAC_2010_KBP_Evaluation_Slot_Filling_Keys/TAC_2010_KBP_Regular-Slot_Assessments_v1.0.0

# test queries from the combined set of 2010 and 2011 queries
devQueries = /u/nlp/data/TAC-KBP2010/test_combined/TAC_KBP_Regular-Slot_Queries_DEVELOPMENT.xml
testQueries = /u/nlp/data/TAC-KBP2010/test_combined/TAC_KBP_Regular-Slot_Queries_TESTING.xml
kbp.goldresponses = /u/nlp/data/TAC-KBP2010/test_combined/TAC_KBP_Regular-Slot_Assessments

# test queries for KBPTester from the 2009 evaluation. No Web data available for these!
#testQueries = /u/nlp/data/TAC-KBP2010/test2009/TAC_2009_KBP_Evaluation_Slot_Filling_List/data/slot_filling_query_list_noGPE.xml
#kbp.goldresponses = /u/nlp/data/TAC-KBP2010/test2009/TAC_2009_KBP_Assessment_Results/data/2010Format

kbScoreFile = kb_score.txt
queryScoreFile = query_score

inference.during.tuning = false
doc.finding.during.tuning = true

# model combination properties
model.combination.enabled = false


#
# Settings valid for the temporal system
#
kbp.temporal = false
kbp.diagnosticmode = false
temporal.startwordsfile= /u/nlp/scr/data/tackbp2011/temporal/startWordsFromFB.ser
temporal.endwordsfile= /u/nlp/scr/data/tackbp2011/temporal/endWordsFromFB.ser
temporal.googlengramsfile = /u/nlp/scr/data/tackbp2011/temporal/googlengrams.ser
temporal.logLevel = SEVERE
temporal.resulttrace = false
temporal.precise = true
temporal.timecombination = BEST_ONLY
temporal.baseline = false
temporal.filterpaths = false
temporal.govverbfilter = false
temporal.useStartEnd = false

